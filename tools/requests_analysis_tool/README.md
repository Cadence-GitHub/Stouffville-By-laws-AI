# Query Log Analysis and Visualization Tool

This tool provides a comprehensive suite of utilities to analyze and visualize user query logs from the Bylaw AI assistant. It consists of two main components:

1.  A powerful **Python script** (`analyze_queries_log.py`) that processes raw `queries_log.json` files, enriches them with detailed metadata using heuristics, embeddings, and LLM-based analysis.
2.  An interactive **web dashboard** (built with HTML, JS, and CSS) that allows for in-depth exploration of the generated analysis file.

---

## Part 1: The Python Analysis Script (`analyze_queries_log.py`)

This script is the engine of the analysis tool. It reads log entries, performs a detailed two-phase analysis, and outputs a structured JSON file ready for visualization.

### Key Features

-   **Two-Phase Processing**: Analysis is split into a fast, local-only phase and a more intensive LLM-based enrichment phase.
-   **Resumable & Idempotent**: The script can be re-run on the same files without duplicating work. It only processes new entries and fills in missing data.
-   **Query Clustering**: Uses `VoyageAI` embeddings and `DBSCAN` clustering to group semantically similar user questions, helping to identify common themes.
-   **Performance Metrics**: Calculates total processing time for each query and identifies the primary bottleneck component.
-   **Retrieval Analysis**: Compares the by-laws retrieved by the RAG system against those ultimately cited in the final answer.
-   **LLM-Powered Evaluation**: Uses Google Gemini models to evaluate query clarity, answer correctness, and other qualitative metrics.

### Setup and Installation

1.  **Dependencies**: The script requires several Python packages. Install them using pip:
    ```bash
    pip install langchain-google-genai langchain_voyageai scikit-learn python-dotenv
    ```

2.  **Environment Variables**: The script requires API keys for the services it uses. Create a `.env` file in the project root or set the following environment variables in your shell:
    -   `GOOGLE_API_KEY`: Your API key for Google Gemini.
    -   `VOYAGE_API_KEY`: Your API key for VoyageAI (used for embeddings).

    Example `.env` file:
    ```
    GOOGLE_API_KEY="AIza..."
    VOYAGE_API_KEY="voya_..."
    ```

### Usage

The script is designed to be run in two distinct phases.

**Phase 1: Initial Processing (Fast, No LLM)**

This phase performs all analysis that does not require an LLM call. It generates embeddings, clusters queries, calculates performance metrics, and sets up the structure of the output file.

```bash
python tools/requests_analysis_tool/analyze_queries_log.py --input backend/queries_log.json
```

-   This will read `backend/queries_log.json`.
-   It will create or update the analysis file at `backend/queries_log.analysis.json`.
-   It will also create/update cache files for embeddings (`.embeddings.json`) and clusters (`.clusters.json`) in the same directory.

**Phase 2: LLM Enrichment (Slower, Requires API Calls)**

This phase fills in the fields that require qualitative analysis from an LLM, such as categorization and quality scores. It intelligently finds entries where this data is `null` and processes only those.

```bash
python tools/requests_analysis_tool/analyze_queries_log.py --input backend/queries_log.json --fill-llm-fields
```

-   This command reads the existing `backend/queries_log.analysis.json` file.
-   It calls the Gemini LLMs to fill in the category and evaluation scores.
-   The process is **resumable**; if it's interrupted, you can simply run it again, and it will pick up where it left off.

---

## Part 2: The Web Visualization Dashboard

The web dashboard is a client-side, single-page application for interactively exploring the data generated by the Python script.

### How to Use

1.  Ensure you have generated a `queries_log.analysis.json` file using the Python script.
2.  Open the `tools/requests_analysis_tool/index.html` file in your web browser.
3.  Click the "Choose File" button and select your `queries_log.analysis.json` file. The dashboard will automatically load and display the data.

### Dashboard Features

#### Key Performance Indicators (KPIs)

At the top of the page, you'll find a summary of key metrics:
-   **Total Queries**: The total number of entries in the log.
-   **Avg Correctness**: The average `answer_correctness_score` (1-5) across all evaluated queries.
-   **Hallucinations**: The total count of queries flagged for containing hallucinations.
-   **Avg. Time**: The average end-to-end processing time for a query.
-   **Lang Mismatches**: The count of queries where the response language did not match the query language.
-   **Unique Categories**: The number of distinct query categories identified by the LLM.

#### Interactive Charts

-   **Query Categories**: A bar chart showing the distribution of queries across different categories, broken down into original and duplicate questions.
-   **Answer Correctness Score**: A doughnut chart illustrating the distribution of correctness scores (1-5).
-   **Performance Bottlenecks**: A doughnut chart identifying which components of the system contribute most to the total processing time.
-   **Query Transform Impact**: A pie chart showing whether the internal query transformation step had a positive or negative impact on retrieving the correct by-laws.
-   **Perfect Answer Rate**: A doughnut chart classifying answers as "Perfect" or "Not Perfect". A "Perfect" answer has top scores for correctness, clarity, and summary, with no flags for hallucination, slowness, or language mismatch.
    -   *This chart is interactive!* Clicking on a slice will filter the **Query Explorer** table below to show only the corresponding queries.

#### Query Explorer

A detailed, searchable, and sortable table of every query log entry.
-   **Flags Column**: Provides a quick visual summary of potential issues for each query:
    -   <i class="fas fa-brain" style="color: #dc3545;"></i>: Hallucination Flag
    -   <i class="fas fa-hourglass-half" style="color: #fd7e14;"></i>: Slow Query
    -   <i class="fas fa-language" style="color: #ffc107;"></i>: Language Mismatch
-   **Interactive Rows**: Click on any row in the table to open a **Detail Modal**.

#### Detail Modal

The modal provides a comprehensive, full-screen view of a single query log entry, including:
-   **Query Comparison**: Side-by-side view of the user's `Original Query` and the system's `Transformed Query`.
-   **Answer Display**: Rendered HTML of the `Filtered Answer` and the `Layman's Answer`.
-   **Retrieval Analysis**: Lists of the by-laws that were originally retrieved and any additional by-laws retrieved after transformation. Bylaws that were cited in the final answer are highlighted in green for easy cross-referencing.
-   **Analysis Vitals**: A complete breakdown of all metadata generated by the script, including all scores, timings, flags, and complexity metrics.

---

## Typical Workflow

1.  **Run Phase 1** to quickly process new logs and get quantitative data.
    `python ... analyze_queries_log.py --input ...`
2.  **Run Phase 2** to enrich the data with LLM-based evaluation. This can be done less frequently.
    `python ... analyze_queries_log.py --input ... --fill-llm-fields`
3.  **Open `index.html`** in a browser and load the `queries_log.analysis.json` file to explore the results.
